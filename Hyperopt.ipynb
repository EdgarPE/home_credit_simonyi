{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries we will use, nump,y pandas, scikit-learn models and metrics, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from hyperopt import STATUS_OK, hp, tpe, fmin\n",
    "import mlflow\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use these metrics to check our model performance\n",
    "\n",
    "metrics = [\n",
    "    ('Precision', precision_score, False),\n",
    "    ('Recall', recall_score, False),\n",
    "#     ('MCC', matthews_corrcoef, False),\n",
    "#     ('F1', f1_score, False),\n",
    "     ('ROC-AUC', roc_auc_score, True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from Google Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('gs://home-credit-simonyi-workshop/input/application_train.subsample.csv')\n",
    "train = pd.read_csv('input/application_train.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use some new fields: **EXT_SOURCE_1, EXT_SOURCE_2, EXT_SOURCE_3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'TARGET'\n",
    "\n",
    "features = [\n",
    "    'DAYS_EMPLOYED',\n",
    "    'DAYS_BIRTH',\n",
    "    'AMT_INCOME_TOTAL',\n",
    "    'AMT_CREDIT',\n",
    "    'CNT_FAM_MEMBERS',\n",
    "    'AMT_ANNUITY',\n",
    "    'EXT_SOURCE_1',\n",
    "    'EXT_SOURCE_2',\n",
    "    'EXT_SOURCE_3',\n",
    "    'NAME_TYPE_SUITE', # categorical\n",
    "    'NAME_INCOME_TYPE', # categorical\n",
    "]\n",
    "\n",
    "for f in features:\n",
    "    train.loc[train[f] == np.inf, f] = np.nan\n",
    "\n",
    "X = train.loc[:, features]\n",
    "y = train.loc[:, target]\n",
    "\n",
    "print(\"Train features DataFrame shape:\", X.shape)\n",
    "print(\"Train target Series shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=train[target], test_size=0.5, random_state=seed)\n",
    "\n",
    "print('Train features shape: ', X_train.shape)\n",
    "print('Train target shape: ', y_train.shape)\n",
    "print('Validate features shape: ', X_valid.shape)\n",
    "print('Validate target shape: ', y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced Pipeline with categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use RandomForestClassifier as our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = list(range(0, 9))\n",
    "num_transform = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "])\n",
    "\n",
    "# Columns can be accessed with names also.\n",
    "cat_feats = ['NAME_TYPE_SUITE', 'NAME_INCOME_TYPE'] \n",
    "cat_transform = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transform, num_feats),\n",
    "    ('cat', cat_transform, cat_feats)\n",
    "])\n",
    "\n",
    "preprocessed_train = preprocessor.fit_transform(X_train)\n",
    "preprocessed_valid = preprocessor.fit_transform(X_valid)\n",
    "\n",
    "classifier = HistGradientBoostingClassifier(max_iter=40, max_depth=12)\n",
    "\n",
    "classifier.fit(preprocessed_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check prediction performance on train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = classifier.predict(preprocessed_train)\n",
    "proba_train = classifier.predict_proba(preprocessed_train)[:,1]\n",
    "\n",
    "for m in metrics:\n",
    "    score = m[1](y_train, proba_train) if m[2] else m[1](y_train, pred_train)\n",
    "    print('%s on train: %.3f' % (m[0], score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course it is close to perfect, but this is expected. But let's check out model on new data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_valid = classifier.predict(preprocessed_valid)\n",
    "proba_valid = classifier.predict_proba(preprocessed_valid)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in metrics:\n",
    "    score = m[1](y_valid, proba_valid) if m[2] else m[1](y_valid, pred_valid)\n",
    "    print('%s on CV: %.3f' % (m[0], score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for hyperoptimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things we need:\n",
    "\n",
    "+ ##### Objective function\n",
    "+ ##### Search space\n",
    "* ##### Search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(hyperparameters):\n",
    "    #Create a model with the hyperparameters\n",
    "    #Train the model\n",
    "    #Evaluate the model\n",
    "    #Return the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space\n",
    "#Evaluate over the search space with the algorithm\n",
    "#Find the best hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
